<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Snail Ren . Blog</title>
    <description>Jie Ren Blog</description>
    <link>snail.ren/</link>
    <atom:link href="snail.ren/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sun, 26 Jun 2016 09:58:28 +0800</pubDate>
    <lastBuildDate>Sun, 26 Jun 2016 09:58:28 +0800</lastBuildDate>
    <generator>Jekyll v3.1.3</generator>
    
      <item>
        <title>XP极限编程</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#xp&quot; id=&quot;markdown-toc-xp&quot;&gt;XP团队组成&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;项目相关环境&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#xp-1&quot; id=&quot;markdown-toc-xp-1&quot;&gt;XP过程&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;思考&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;协作&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;1、信任&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;2、坐到一起&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-5&quot; id=&quot;markdown-toc-section-5&quot;&gt;3、真实客户参与&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-6&quot; id=&quot;markdown-toc-section-6&quot;&gt;4、统一协作语言&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-7&quot; id=&quot;markdown-toc-section-7&quot;&gt;5、站立会议&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-8&quot; id=&quot;markdown-toc-section-8&quot;&gt;6、编码规范&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-9&quot; id=&quot;markdown-toc-section-9&quot;&gt;7、迭代演示&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-10&quot; id=&quot;markdown-toc-section-10&quot;&gt;8、汇报&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-11&quot; id=&quot;markdown-toc-section-11&quot;&gt;发布&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section-12&quot; id=&quot;markdown-toc-section-12&quot;&gt;1、全部完成&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#bug&quot; id=&quot;markdown-toc-bug&quot;&gt;2、没有bug&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-13&quot; id=&quot;markdown-toc-section-13&quot;&gt;3、版本控制&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-14&quot; id=&quot;markdown-toc-section-14&quot;&gt;4、十分钟构建&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-15&quot; id=&quot;markdown-toc-section-15&quot;&gt;5、持续集成&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-16&quot; id=&quot;markdown-toc-section-16&quot;&gt;6、代码集体所有制&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-17&quot; id=&quot;markdown-toc-section-17&quot;&gt;7、文档&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-18&quot; id=&quot;markdown-toc-section-18&quot;&gt;计划&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section-19&quot; id=&quot;markdown-toc-section-19&quot;&gt;1、愿景&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-20&quot; id=&quot;markdown-toc-section-20&quot;&gt;2、发布计划&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-21&quot; id=&quot;markdown-toc-section-21&quot;&gt;3、计划博弈&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-22&quot; id=&quot;markdown-toc-section-22&quot;&gt;4、风险管理&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-23&quot; id=&quot;markdown-toc-section-23&quot;&gt;5、迭代计划&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-24&quot; id=&quot;markdown-toc-section-24&quot;&gt;6、松弛&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-25&quot; id=&quot;markdown-toc-section-25&quot;&gt;7、故事&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-26&quot; id=&quot;markdown-toc-section-26&quot;&gt;8、估算&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-27&quot; id=&quot;markdown-toc-section-27&quot;&gt;开发&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section-28&quot; id=&quot;markdown-toc-section-28&quot;&gt;1、增量式需求&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-29&quot; id=&quot;markdown-toc-section-29&quot;&gt;2、客户测试&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-30&quot; id=&quot;markdown-toc-section-30&quot;&gt;3、测试驱动开发&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-31&quot; id=&quot;markdown-toc-section-31&quot;&gt;4、重构&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-32&quot; id=&quot;markdown-toc-section-32&quot;&gt;5、简单设计&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-33&quot; id=&quot;markdown-toc-section-33&quot;&gt;6、增量设计和架构&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-34&quot; id=&quot;markdown-toc-section-34&quot;&gt;7、试验方案&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-35&quot; id=&quot;markdown-toc-section-35&quot;&gt;8、性能优化&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-36&quot; id=&quot;markdown-toc-section-36&quot;&gt;9、探索性测试&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;xp&quot;&gt;XP团队组成&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/blog/XP.png&quot; alt=&quot;JMM&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;项目相关环境&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;利益相关者：与PM一样，对项目进行管理&lt;/li&gt;
  &lt;li&gt;执行发起人：最终客户（必须定期演示）&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;xp-1&quot;&gt;XP过程&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/blog/XP-process.png&quot; alt=&quot;JMM&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;思考&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;结对编程&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;结对编程中，一个人写，一个人思考。结对编程可以防止被打扰，可以提高精力&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;精力充沛的工作&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;按时下班，不把工作带回家，健康饮食，经常锻炼。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;信息化工作场所&lt;/p&gt;

    &lt;p&gt;通过各种信息（图表等）贴在工作场所，以随时了解项目进度、当前情况，同时通过图表监控、测评项目。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;根源分析&lt;/p&gt;

    &lt;p&gt;遇到问题不要想责备，问自己为什么会出现这个问题，寻求问题根源&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;回顾&lt;/p&gt;

    &lt;p&gt;在一次会议中引导一个人说过话，那么他继续说话的可能性就会加大&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;协作&lt;/h2&gt;

&lt;h3 id=&quot;section-3&quot;&gt;1、信任&lt;/h3&gt;

&lt;p&gt;团队内部需要和谐团结，与客户（关系人）的关系弄好。可以采用：客户与程序员换位思考、程序员与测试员换位思考、共同进餐、团队持续性（以团队为单位做项目）。坦然面对错误，及早与关系人坦白困难、错误，共同面对问题。定期交付，维护与关系人的关系。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;2、坐到一起&lt;/h3&gt;

&lt;p&gt;团队的所有成员需要在同一个场所办公。现场客户、程序员、测试员等。这样可以及时交流、高效沟通。但是也提供一个私密的小房间供打电话、聊天等。&lt;/p&gt;

&lt;h3 id=&quot;section-5&quot;&gt;3、真实客户参与&lt;/h3&gt;

&lt;p&gt;有了真实用户的参与，就不会让自己陷入各种细节。扩大自己的视角。利用他们在实际中如何使用软件、他们的领域知识，可以让你交付一款真正有用的产品。&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;4、统一协作语言&lt;/h3&gt;

&lt;p&gt;采用同一种语言，可以较少程序员与客户专家的沟通障碍。比如程序员采用客户领域的术语进行图表的绘制、命名。&lt;/p&gt;

&lt;h3 id=&quot;section-7&quot;&gt;5、站立会议&lt;/h3&gt;

&lt;p&gt;在一个固定的时间召开。每次不要超过十分钟。时间不一定在早上，可以上午结束的时候。会议由每个人讲需要让整个团队知道的事情。可以以“我昨天做了什么、今天打算做什么、遇到了什么问题”的格式，也不一定得按照这个格式。&lt;/p&gt;

&lt;h3 id=&quot;section-8&quot;&gt;6、编码规范&lt;/h3&gt;

&lt;p&gt;编码的规范可以包含：开发实践、工具和快捷键、文件和目录布局、构建和约定、错误处理和断言、实践和日志记录方式、设计约定等。规范的设计，以“1、指定可以接受的最小标准集合 2、关注一致性和共识，而不是完美”。&lt;/p&gt;

&lt;p&gt;在制定规范后，如果有人没有按照规范，可以和他谈：认为这个规范怎么样，为什么没有按照规范。&lt;/p&gt;

&lt;h3 id=&quot;section-9&quot;&gt;7、迭代演示&lt;/h3&gt;

&lt;p&gt;迭代演示可以降低风险，增加活力，促进团队进步。XP的核心就是定期交付。在演示的过程中，可以解释为什么和原计划不同，有什么变化。若客户具体到某一细节，可以说在演示结束后由项目经理解释。在演示结束后问客户：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1、到目前为止客户是否满意。&lt;/li&gt;
  &lt;li&gt;2、是否可以继续。如果在演示中，客户提到需要添加新特性，则说：会后由产品经理负责特性的把关与添加。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-10&quot;&gt;8、汇报&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;进行良好的汇报，可以增加客户对团队的信任，更相信团队的决策。&lt;/li&gt;
  &lt;li&gt;进展汇报：愿景陈述、每周演示、发布和迭代计划、burn-up图。如果需要更详细，可以提供路线图   、状态电子邮件&lt;/li&gt;
  &lt;li&gt;管理汇报：生产率、产能、缺陷、时间利用率&lt;/li&gt;
  &lt;li&gt;不要汇报：源代码行数、故事数、开发速度、代码质量等&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-11&quot;&gt;发布&lt;/h2&gt;

&lt;h3 id=&quot;section-12&quot;&gt;1、全部完成&lt;/h3&gt;

&lt;p&gt;全部完成是指可以发布使用。平时以全部完成来要求团队，可以避免大量难以预计的收尾工作。完成包含测试完成、编码完成、设计完成、集成完成、成功构建、安装、移植、评审完成、修复完成、用户接受。TDD可以促使设计、测试、编程同步完成。&lt;/p&gt;

&lt;h3 id=&quot;bug&quot;&gt;2、没有bug&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; a.编写更少的bug：采用TDD，可以减少一定bug。或者通过大量技术和组织方法尽量减少bug的生成。
 b.消除bug的温床：通过重构设计不良的代码可以减少bug
 c.修复bug：尽早修复bug，越到最后代码修复的成本就越大。
 d.测试过程：通过探索性测试，以不寻常的方式进行测试，可以检测预料之外的bug
 e.修正过程：对自己进行总结，查找为什么会出现bug，对自己的编码过程就行改正。
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-13&quot;&gt;3、版本控制&lt;/h3&gt;

&lt;p&gt;版本控制可以管理项目，可以进行回退等&lt;/p&gt;

&lt;h3 id=&quot;section-14&quot;&gt;4、十分钟构建&lt;/h3&gt;

&lt;p&gt;自动化构建，可以避免很多问题。可以利用ant、make等进行构建。当项目在很小的时候进行自动化构建。尽量不要让构建的时间太长。&lt;/p&gt;

&lt;h3 id=&quot;section-15&quot;&gt;5、持续集成&lt;/h3&gt;

&lt;p&gt;持续集成能够减少很多隐藏的发布时间。每隔几小时进行集成，保证构建、测试及其他发布的基础组件都能及时更新。这样可以降低发布难度。&lt;/p&gt;

&lt;h3 id=&quot;section-16&quot;&gt;6、代码集体所有制&lt;/h3&gt;

&lt;p&gt;这样可以让整个团队为所有代码复制。每个人都可以改进别人的代码。这样可以在一个人离开时，团队还能继续推进。实在无法实施集体所有制，可以通过结对编程折中。&lt;/p&gt;

&lt;h3 id=&quot;section-17&quot;&gt;7、文档&lt;/h3&gt;

&lt;p&gt;文档不用很多，但是因为有更好有效的交流方式，不是偷懒的借口。不需要特定去做什么文档，如果一些文档有商业价值，将其安排为一个user story进行操作。&lt;/p&gt;

&lt;h2 id=&quot;section-18&quot;&gt;计划&lt;/h2&gt;

&lt;h3 id=&quot;section-19&quot;&gt;1、愿景&lt;/h3&gt;

&lt;p&gt;揭示项目正在朝哪个方向前进，以及为什么朝这个方向前进。制定愿景时，可以从：项目应该完成什么、项目为什么有价值、项目的成功标准是什么。愿景指定后就推广出去，贴在工作场所，要求客户一同参与愿景指定。如果有了一份清晰、有说服力的远景，则很容易为故事安排优先级。同时团队成员了解项目的重要程度，有助于提高士气。&lt;/p&gt;

&lt;h3 id=&quot;section-20&quot;&gt;2、发布计划&lt;/h3&gt;

&lt;p&gt;在接受项目时，尽量只做一个项目，不要几个一起做。同时尽早发布，经常发布，将最有价值的特性先发布出去，有助于提升商业价值。在发布的时候，不要全部把所有的发布出去，为自己留一些余地，不要一次性全部发布。计划需要不断调整，让客户清楚你的计划。可以以时间为标准进行计划。&lt;/p&gt;

&lt;h3 id=&quot;section-21&quot;&gt;3、计划博弈&lt;/h3&gt;

&lt;p&gt;在计划生成后，对计划的具体安排需要讨论。在对计划进行实施时，良好的计划博弈，是让程序员觉得自己的专业知识对计划进行了贡献，客户觉得自己的领域知识做出了优先级划定。&lt;/p&gt;

&lt;h3 id=&quot;section-22&quot;&gt;4、风险管理&lt;/h3&gt;

&lt;p&gt;随时对风险进行把控、预测、应对。及时当开发中断也能成功交付，这样以后公司会更加信任你。&lt;/p&gt;

&lt;h3 id=&quot;section-23&quot;&gt;5、迭代计划&lt;/h3&gt;

&lt;p&gt;每次选择最后价值的特性加入其中进行迭代。一次迭代，由：演示演一轮迭代、回顾前一轮迭代、制定迭代计划、承担故事的交付、开发故事、准备发布。一般在一周完成。在发布了迭代任务后，对任务进行跟踪。&lt;/p&gt;

&lt;h3 id=&quot;section-24&quot;&gt;6、松弛&lt;/h3&gt;

&lt;p&gt;在迭代中添加松弛制度，增加研究时间，不要太紧。&lt;/p&gt;

&lt;h3 id=&quot;section-25&quot;&gt;7、故事&lt;/h3&gt;

&lt;p&gt;以用户为中心，用一个个卡片来整理故事。太大的故事进行拆分。故事由客户进行把关。同时也可以包含文档故事、非功能故事、bug故事、试验故事、估算、会议等。将故事分小，可以频繁交付完整特性。&lt;/p&gt;

&lt;h3 id=&quot;section-26&quot;&gt;8、估算&lt;/h3&gt;

&lt;p&gt;做良好的估算，在每次迭代中都是一致和可预测的。估算时，对故事进行充分分析和挖掘。&lt;/p&gt;

&lt;h2 id=&quot;section-27&quot;&gt;开发&lt;/h2&gt;

&lt;h3 id=&quot;section-28&quot;&gt;1、增量式需求&lt;/h3&gt;
&lt;p&gt;客户可能开始不能确定全部的需求，不用担心。那就开始在已经确定的上面工作。但是客户的每次反馈都需要记录，客户签字，防止客户否认&lt;/p&gt;

&lt;h3 id=&quot;section-29&quot;&gt;2、客户测试&lt;/h3&gt;
&lt;p&gt;对于每个特性，创建客户测试可以通过描述、演示、开发进行。描述是由客户详细、举例描述功能。让用户领导进行客户测试，引导他们参与&lt;/p&gt;

&lt;h3 id=&quot;section-30&quot;&gt;3、测试驱动开发&lt;/h3&gt;
&lt;p&gt;在开发前先写测试，这样你在开发时，会自动对你的开发过程进行把控&lt;/p&gt;

&lt;h3 id=&quot;section-31&quot;&gt;4、重构&lt;/h3&gt;
&lt;p&gt;在平时对代码进行重构，持续提高代码质量&lt;/p&gt;

&lt;h3 id=&quot;section-32&quot;&gt;5、简单设计&lt;/h3&gt;

&lt;h3 id=&quot;section-33&quot;&gt;6、增量设计和架构&lt;/h3&gt;

&lt;h3 id=&quot;section-34&quot;&gt;7、试验方案&lt;/h3&gt;

&lt;h3 id=&quot;section-35&quot;&gt;8、性能优化&lt;/h3&gt;

&lt;h3 id=&quot;section-36&quot;&gt;9、探索性测试&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;XP的价值：&lt;strong&gt;简单、勇气、沟通、反馈、尊重&lt;/strong&gt;。
在实践中避免浪费，若项目一定会失败，则尽早失败。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Sun, 26 Jun 2016 19:00:00 +0800</pubDate>
        <link>snail.ren/java-concurrent programming</link>
        <guid isPermaLink="true">snail.ren/java-concurrent programming</guid>
        
        
        <category>se</category>
        
      </item>
    
      <item>
        <title>Sqoop Consume Teiid  </title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#downloading-and-installing-sqoop&quot; id=&quot;markdown-toc-downloading-and-installing-sqoop&quot;&gt;Downloading and installing Sqoop&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#installing-sqoop&quot; id=&quot;markdown-toc-installing-sqoop&quot;&gt;Installing Sqoop&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#step1-download&quot; id=&quot;markdown-toc-step1-download&quot;&gt;Step.1 Download&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sqoop-consume-teiid&quot; id=&quot;markdown-toc-sqoop-consume-teiid&quot;&gt;Sqoop consume Teiid&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#system-requirements&quot; id=&quot;markdown-toc-system-requirements&quot;&gt;System requirements&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sqoop-demonstrations&quot; id=&quot;markdown-toc-sqoop-demonstrations&quot;&gt;Sqoop Demonstrations&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#copy-teiid-jdbc-to-sqoophomelib&quot; id=&quot;markdown-toc-copy-teiid-jdbc-to-sqoophomelib&quot;&gt;1. Copy teiid-jdbc to $SQOOP_HOME/lib&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#import-data-to-hdfs&quot; id=&quot;markdown-toc-import-data-to-hdfs&quot;&gt;2. Import data to HDFS&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#check-hdfs&quot; id=&quot;markdown-toc-check-hdfs&quot;&gt;3. Check HDFS&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;downloading-and-installing-sqoop&quot;&gt;Downloading and installing Sqoop&lt;/h2&gt;
&lt;p&gt;Sqoop can import/export data from Database, like mysql, sql server, etc.&lt;/p&gt;

&lt;h3 id=&quot;installing-sqoop&quot;&gt;Installing Sqoop&lt;/h3&gt;
&lt;p&gt;Acturally, the installation is quite easy.&lt;/p&gt;

&lt;h4 id=&quot;step1-download&quot;&gt;Step.1 Download&lt;/h4&gt;

&lt;p&gt;You can get Sqoop from http://sqoop.apache.org. Compatible Sqoop version is needed to match you Hadoop version.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ wget http://apache.fayea.com/sqoop/1.4.6/sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz
$ tar -xvf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;####Step.2  Configure&lt;/p&gt;

&lt;p&gt;Just set environment variable, that’s all.&lt;/p&gt;

&lt;p&gt;Edit &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/profile&lt;/code&gt;, root user is needed.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export SQOOP_HOME=/home/userName/sqoop-1.4.6.bin__hadoop-2.0.4-alpha
export PATH = $SQOOP_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;After edit&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ source /etc/profile
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;sqoop-consume-teiid&quot;&gt;Sqoop consume Teiid&lt;/h2&gt;

&lt;p&gt;This quickstart demonstrates how to import data from teiid to HDFS by Sqoop.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;VDB:   Portfolio&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;system-requirements&quot;&gt;System requirements&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Java 1.7+&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/teiid/teiid-quickstarts/blob/master/README.adoc#_downloading_and_installing_teiid&quot;&gt;Teiid Server&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://snail.ren/java-concurrent%20programming&quot;&gt;Hadoop&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Sqoop&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;NOTE: This example relies upon the vdb-datafederation example and that it needs to be deployed prior to running this example. Therefore, read the vdb-datafederation’s &lt;a href=&quot;https://github.com/teiid/teiid-quickstarts/blob/master/vdb-datafederation/README.adoc&quot;&gt;README.md&lt;/a&gt; and follow its directions before continuing.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;sqoop-demonstrations&quot;&gt;Sqoop Demonstrations&lt;/h3&gt;

&lt;h4 id=&quot;copy-teiid-jdbc-to-sqoophomelib&quot;&gt;1. Copy teiid-jdbc to $SQOOP_HOME/lib&lt;/h4&gt;

&lt;p&gt;You need download Teiid JDBC Driver from http://teiid.jboss.org/downloads/ and copy it to $SQOOP_HOME/lib&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cp teiid-9.0.0.Final-jdbc.jar $SQOOP_HOME/lib
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;import-data-to-hdfs&quot;&gt;2. Import data to HDFS&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sqoop import --connect jdbc:teiid:Portfolio@mm://127.0.0.1:31000 --driver org.teiid.jdbc.TeiidDriver --username odataUser --password password1! --table product 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;check-hdfs&quot;&gt;3. Check HDFS&lt;/h4&gt;

&lt;p&gt;Now, you can verify that whether the data from VDB is imported to HDFS.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Verify HDFS&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ hadoop dfs -ls /user/username/product
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Verify Data&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ hadoop dfs -get /user/username/product ./result
$ cat result/part-m-*
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

</description>
        <pubDate>Sat, 25 Jun 2016 18:00:00 +0800</pubDate>
        <link>snail.ren/java-concurrent programming</link>
        <guid isPermaLink="true">snail.ren/java-concurrent programming</guid>
        
        
        <category>bigdata</category>
        
      </item>
    
      <item>
        <title>Hadoop and Spark and Hive Installation</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#downloading-and-installing-hadoop&quot; id=&quot;markdown-toc-downloading-and-installing-hadoop&quot;&gt;Downloading and installing Hadoop&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#installing-hadoop-2x-to-red-hat-linux&quot; id=&quot;markdown-toc-installing-hadoop-2x-to-red-hat-linux&quot;&gt;Installing Hadoop 2.x to Red Hat Linux&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#step1-prerequisites&quot; id=&quot;markdown-toc-step1-prerequisites&quot;&gt;Step.1 Prerequisites&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#step3-configure&quot; id=&quot;markdown-toc-step3-configure&quot;&gt;Step.3 Configure&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#step4-start&quot; id=&quot;markdown-toc-step4-start&quot;&gt;Step.4 Start&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#step5-stop&quot; id=&quot;markdown-toc-step5-stop&quot;&gt;Step.5 Stop&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#downloading-and-installing-apache-hive&quot; id=&quot;markdown-toc-downloading-and-installing-apache-hive&quot;&gt;Downloading and installing Apache Hive&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#downloading-and-installing-apache-spark&quot; id=&quot;markdown-toc-downloading-and-installing-apache-spark&quot;&gt;Downloading and installing Apache Spark&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;downloading-and-installing-hadoop&quot;&gt;Downloading and installing Hadoop&lt;/h2&gt;

&lt;h3 id=&quot;installing-hadoop-2x-to-red-hat-linux&quot;&gt;Installing Hadoop 2.x to Red Hat Linux&lt;/h3&gt;

&lt;p&gt;This section including step by step procedures for installing &lt;code class=&quot;highlighter-rouge&quot;&gt;Hadoop 2.6.4&lt;/code&gt; to Fedora 23, and configuring a Single Node Setup.&lt;/p&gt;

&lt;h4 id=&quot;step1-prerequisites&quot;&gt;Step.1 Prerequisites&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ uname -a
Linux localhost 4.2.3-300.fc23.x86_64 #1 SMP Mon Oct 5 15:42:54 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux


$ java -version
java version &quot;1.7.0_60&quot;
Java(TM) SE Runtime Environment (build 1.7.0_60-b19)
Java HotSpot(TM) 64-Bit Server VM (build 24.60-b09, mixed mode)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;####Step.2 Download and Install&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ wget http://apache.fayea.com/hadoop/common/hadoop-2.6.4/hadoop-2.6.4.tar.gz
$ tar -xvf hadoop-2.6.4.tar.gz
$ cd hadoop-2.6.4
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Edit &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/profile&lt;/code&gt;, root user is needed.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#set hadoop
export JAVA_LIBRARY_PATH=/home/renjie/work/hadoop/lib/native
export HADOOP_HOME=/home/userName/hadoop-2.6.4
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;After edit&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;source /etc/profile
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;step3-configure&quot;&gt;Step.3 Configure&lt;/h4&gt;

&lt;p&gt;Edit &lt;code class=&quot;highlighter-rouge&quot;&gt;etc/hadoop/hadoop-env.sh&lt;/code&gt;, comment out JAVA_HOME, make sure it point to a valid Java Home:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export JAVA_HOME=/usr/java/jdk1.7.0_60
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;NOTE: Java 1.6 or higher is needed.&lt;/p&gt;

&lt;p&gt;Edit &lt;code class=&quot;highlighter-rouge&quot;&gt;etc/hadoop/core-site.xml&lt;/code&gt;, add the following properties in :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;file:/home/userName/hadoop-2.6.4/tmp&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hadoop.proxyuser.userName.hosts&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;*&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hadoop.proxyuser.userName.groups&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;*&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;NOTE: the property’s value should match to your’s setting.&lt;/p&gt;

&lt;p&gt;Edit &lt;code class=&quot;highlighter-rouge&quot;&gt;etc/hadoop/hdfs-site.xml&lt;/code&gt;, add the following property in:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;dfs.namenode.name.dir&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;file:/home/userName/hadoop-2.6.4/tmp/dfs/name&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;dfs.datanode.data.dir&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;file:/home/userName/hadoop-2.6.4/tmp/dfs/data&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Format a new distributed-filesystem via execute&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hadoop-2.6.4/bin/hadoop namenode -format
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;step4-start&quot;&gt;Step.4 Start&lt;/h4&gt;

&lt;p&gt;Start all hadoop services via execute&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ./sbin/start-all.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;NOTE: there are 5 java processes which represent 5 services be started: &lt;code class=&quot;highlighter-rouge&quot;&gt;NameNode&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;SecondaryNameNode&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;DataNode&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;JobTracker&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;TaskTracker&lt;/code&gt;. Execute `jps -l’ to check the java processes:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ jps -l
4056 org.apache.hadoop.hdfs.server.namenode.NameNode
4271 org.apache.hadoop.hdfs.server.datanode.DataNode
4483 org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode
4568 org.apache.hadoop.mapred.JobTracker
4796 org.apache.hadoop.mapred.TaskTracker
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;NOTE: &lt;code class=&quot;highlighter-rouge&quot;&gt;NameNode&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;JobTracker&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;TaskTracker&lt;/code&gt; has relevant Web Consoles for View and Monitor the serivces. Web Access URLs for Services:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;http://localhost:50030/   for the Jobtracker
http://localhost:50070/   for the Namenode
http://localhost:50060/   for the Tasktracker
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;step5-stop&quot;&gt;Step.5 Stop&lt;/h4&gt;

&lt;p&gt;Stop all hadoop services via execute&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# ./sbin/stop-all.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;downloading-and-installing-apache-hive&quot;&gt;Downloading and installing Apache Hive&lt;/h2&gt;

&lt;p&gt;This section including step by step procedures for installing Apache Hive and set up HiveServer2.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step.1 Prerequisites&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Hadoop is the prerequisite, refer to above steps to install and start Hadoop.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step.2 Install&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ tar -xvf apache-hive-1.2.1-bin.tar.gz
$ cd apache-hive-1.2.1-bin
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Step.3 Configure&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Create a &lt;code class=&quot;highlighter-rouge&quot;&gt;hive-env.sh&lt;/code&gt; under &lt;code class=&quot;highlighter-rouge&quot;&gt;conf&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd conf/
$ cp hive-env.sh.template hive-env.sh
$ vim hive-env.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;comment out HADOOP_HOME and make sure point to a valid Hadoop home, for example:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;HADOOP_HOME=/home/kylin/server/hadoop-1.2.1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Navigate to Hadoop Home, create ‘/tmp’ and ‘/user/hive/warehouse’ and chmod g+w in HDFS before running Hive:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ./bin/hadoop fs -mkdir /tmp
$ ./bin/hadoop fs -mkdir /user/hive/warehouse
$ ./bin/hadoop fs -chmod g+w /tmp
$ ./bin/hadoop fs -chmod g+w /user/hive/warehouse
$ ./bin/hadoop fs -chmod 777 /tmp/hive
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;NOTE: Restart Hadoop services is needed, this for avoid &lt;code class=&quot;highlighter-rouge&quot;&gt;java.io.IOException: Filesystem closed&lt;/code&gt; in DFSClient check Open.&lt;/p&gt;

&lt;p&gt;Create a &lt;code class=&quot;highlighter-rouge&quot;&gt;hive-site.xml&lt;/code&gt; file under conf folder&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd apache-hive-1.2.1-bin/conf/
$ touch hive-site.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Edit the &lt;code class=&quot;highlighter-rouge&quot;&gt;hive-site.xml&lt;/code&gt;, add the following content:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&amp;gt;&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hive.server2.thrift.min.worker.threads&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;5&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hive.server2.thrift.max.worker.threads&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;500&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hive.server2.thrift.port&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;10000&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hive.server2.thrift.bind.host&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;0.0.0.0&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;NOTE: there are other Optional properties, more refer to https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2[Setting+Up+HiveServer2]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step.4 Start HiveServer2&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ./bin/hiveserver2
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;downloading-and-installing-apache-spark&quot;&gt;Downloading and installing Apache Spark&lt;/h2&gt;

&lt;p&gt;This section including step by step procedures for installing Apache Spark in Single Node. You can install Spark from source or Pre-build package. In this section, we use &lt;strong&gt;Spark 1.6.1 Pre-built for Hadoop 2.6&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Spark runs on Java 7+, Python 2.6+ and R 3.1+. For the Scala API, Spark 1.6.1 uses Scala 2.10. You will need to use a compatible Scala version (2.10.x).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step.1 Install Scala&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1) Download Scala&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ wget http://downloads.lightbend.com/scala/2.11.8/scala-2.11.8.tgz
$ tar -zxvf scala-2.11.8.tgz
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;2)Configure&lt;/p&gt;

&lt;p&gt;Edit &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/profile&lt;/code&gt;, root user is needed.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export SCALA_HOME=/home/userName/scala-2.11.8
export PATH=$PATH:$SCALA_HOME/bin
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;After edit&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;source /etc/profile
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Step.2 Install Spark&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;You will need to use a compatible Spark version to match Hadoop in your system.&lt;/p&gt;

&lt;p&gt;1) Download Spark&lt;/p&gt;

&lt;p&gt;You can download Spark from http://spark.apache.org/downloads.html.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ tar -xvf spark-1.6.1-bin-hadoop2.6.tgz
$ cd spark-1.6.1-bin-hadoop2.6
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;2) Configure&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Edit &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/profile&lt;/code&gt;, root user is needed.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#set SPARK
export SPARK_HOME=/home/username/spark-1.6.1-bin-hadoop2.6
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;After edit&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;source /etc/profile
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Copy conf/spark-env.sh.template to conf/spark-env.sh, edit the &lt;code class=&quot;highlighter-rouge&quot;&gt;spark-env.sh&lt;/code&gt;, add the following content:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export JAVA_HOME=/usr/local/java
export SCALA_HOME=/home/userName/scala-2.11.8
export SPARK_MASTER_IP=127.0.0.1
export SPARK_LOCAL_IP=127.0.0.1
export SPARK_WORKER_MEMORY=2000m
export HADOOP_CONF_DIR=/home/userName/hadoop-2.6.4/etc/hadoop
export SPARK_WORKER_CORES=1
export SPARK_WORKER_INSTANCES=1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Copy conf/slaves.template to conf/slaves, edit the &lt;code class=&quot;highlighter-rouge&quot;&gt;slaves&lt;/code&gt;, add the following content:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;localhost
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Step.3 Start Spark&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd $SPARK_HOME
$ ./sbin/start-all.sh 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

</description>
        <pubDate>Fri, 24 Jun 2016 04:00:00 +0800</pubDate>
        <link>snail.ren/java-concurrent programming</link>
        <guid isPermaLink="true">snail.ren/java-concurrent programming</guid>
        
        
        <category>bigdata</category>
        
      </item>
    
      <item>
        <title>Java Concurrent Programming4: Safe Collection  </title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;四、线程安全的容器类&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#map&quot; id=&quot;markdown-toc-map&quot;&gt;1.Map&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#collection&quot; id=&quot;markdown-toc-collection&quot;&gt;2. Collection&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#stringbufferstringbuilder&quot; id=&quot;markdown-toc-stringbufferstringbuilder&quot;&gt;3.StringBuffer和StringBuilder&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section&quot;&gt;四、线程安全的容器类&lt;/h2&gt;
&lt;p&gt;Java编码中，我们经常需要用到容器来编程。在并发环境下，Java提供一些已有容器能够支持并发。&lt;/p&gt;

&lt;h3 id=&quot;map&quot;&gt;1.Map&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/assets/blog/Collection-map.png&quot; alt=&quot;Map&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在Map类中，提供两种线程安全容器。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;java.util.Hashtable&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hashtable和HashMap类似，都是散列表，存储键值对映射。主要区别在于Hashtable是线程安全的。当我们查看Hashtable源码的时候，可以看到Hashtable的方法都是通过synchronized来进行方法层次的同步，以达到线程安全的作用。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;java.util.concurrent.ConcurrentHashMap&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ConcurrentHashMap是性能更好的散列表。在兼顾线程安全的同时，相对于Hashtable，在效率上有很大的提高。我们可以猜想，Hashtable的线程安全实现是对方法进行synchronized，很明显可以通过其他并发方式，如ReentrantLock进行优化。而ConcurrentHashMap正是采用了ReentrantLock。运用锁分离技术，即在代码块上加锁，而不是方法上加。同时ConcurrentHashMap的一个特色是允许多个修改并发操作。这就有意思了，我们知道一般写都是互斥的，为什么这个还能多个同时写呢？那是因为ConcurrentHashMap采用了内部使用段机制，将ConcurrentHashMap分成了很多小段。只要不在一个小段上写就可以并发写。&lt;/p&gt;

&lt;h3 id=&quot;collection&quot;&gt;2. Collection&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/blog/Collection-collection.png&quot; alt=&quot;Collection&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Collection部分主要是运用的CopyOnWrite机制，即写时复制机制。从字面上就能理解什么意思，就是当我们往一个容器里添加元素的时候，先对这个容器进行一次复制，对副本进行写操作。写操作结束后，将原容器的引用指向新副本容器，就完成了写的刷新。&lt;/p&gt;

&lt;p&gt;从它的实现原理，我们可以看出这种机制是存在缺点的。&lt;/p&gt;

&lt;p&gt;1.内存占用：毫无疑问，每次写时需要首先复制一遍原容器，假如复制了很多，或者本身原容器就比较大，那么肯定会占用很多内存。可以采用压缩容器中的元素来防止内存消耗过大。&lt;/p&gt;

&lt;p&gt;2.数据一致性问题：当我们在副本中进行写操组时，只能在最终结束后使数据同步，不能实时同步&lt;/p&gt;

&lt;p&gt;可以看到，这种机制适用于&lt;strong&gt;读操作多，写操作少&lt;/strong&gt;的应用场景。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;java.util.concurrent.CopyOnWriteArrayList&lt;/p&gt;

    &lt;p&gt;Collection类的线程安全容器主要都是利用的ReentrantLock实现的线程安全，CopyOnWriteArrayList也不例外。在并发写的时候，需要获取lock。读的时候不需要进行lock&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;java.util.concurrent.CopyOnWriteArraySet&lt;/p&gt;

    &lt;p&gt;CopyOnWriteArraySet的实现就是基于CopyOnWriteArrayList实现的，采用的装饰器进行实现。二者的区别和List和Set的区别一样。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vector&lt;/p&gt;

    &lt;p&gt;一般我们都不用Vector了，不过它确实也是线程安全的。相对于其他容器，能够提供随机访问功能。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;stringbufferstringbuilder&quot;&gt;3.StringBuffer和StringBuilder&lt;/h3&gt;

&lt;p&gt;我们知道，String在进行+操作的时候，原生的String会重新新建一个String对象来完成字符串拼接，明显这种操作多了的话会加重服务器负担。因此我们需要的时候就会用StringBuffer和StringBuilder。这二者有什么区别呢？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;StringBuffer&lt;/strong&gt;是线程安全的，StringBuilder不是。从StringBuffer的源码可以看到，它采用的是对方法进行synchronized实现的同步。但是加了同步机制，肯定会对性能有一定影响。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;高并发情况下，对数据安全有需求，则用StringBuffer，否则用StringBuilder&lt;/p&gt;
&lt;/blockquote&gt;

</description>
        <pubDate>Tue, 21 Jun 2016 07:00:00 +0800</pubDate>
        <link>snail.ren/java-concurrent programming</link>
        <guid isPermaLink="true">snail.ren/java-concurrent programming</guid>
        
        
        <category>concurrent</category>
        
      </item>
    
      <item>
        <title>Java Concurrent Programming3: Thread Safe  </title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#thread&quot; id=&quot;markdown-toc-thread&quot;&gt;三、Thread安全&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#javajmm&quot; id=&quot;markdown-toc-javajmm&quot;&gt;1. Java内存模型JMM与多线程&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#synchronized&quot; id=&quot;markdown-toc-synchronized&quot;&gt;2. synchronized&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#lock-and-reentrantlock&quot; id=&quot;markdown-toc-lock-and-reentrantlock&quot;&gt;3. Lock and ReentrantLock&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#reentrantlock&quot; id=&quot;markdown-toc-reentrantlock&quot;&gt;ReentrantLock&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#readwritelock-and-reentrantreadwritelock&quot; id=&quot;markdown-toc-readwritelock-and-reentrantreadwritelock&quot;&gt;ReadWriteLock and ReentrantReadWriteLock&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#stampedlock&quot; id=&quot;markdown-toc-stampedlock&quot;&gt;StampedLock&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#volatile&quot; id=&quot;markdown-toc-volatile&quot;&gt;4. volatile修饰变量&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#atomic&quot; id=&quot;markdown-toc-atomic&quot;&gt;5.原子操作atomic&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;thread&quot;&gt;三、Thread安全&lt;/h2&gt;
&lt;p&gt;线程安全不是指数据本身或者数据传输中的安全，而主要是指在高并发多线程的访问过程中，多线程对数据本身的读写所造成的数据不一致、脏数据等情况的避免。&lt;/p&gt;

&lt;h3 id=&quot;javajmm&quot;&gt;1. Java内存模型JMM与多线程&lt;/h3&gt;

&lt;p&gt;在Java里，JLS定义了Java的统一的内存管理模型JMM（Java Memory Model）。JMM规定JVM中有&lt;strong&gt;主内存（Main Memory）&lt;/strong&gt;以及&lt;strong&gt;工作内存（Work Memory）&lt;/strong&gt;。&lt;strong&gt;主内存&lt;/strong&gt;就是我们所说的堆内存，存放类的实例、静态数据等，由多线程共享。&lt;strong&gt;工作内存&lt;/strong&gt;是各个线程自己的“小金库”，存放自己从主内存拷贝过来的变量以及局部变量。既然是小金库，那么就只能自己访问，其他线程无法访问。如果线程之间要相互通信，就只能用主内存中的共享变量进行通信。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/blog/JMM.png&quot; alt=&quot;JMM&quot; /&gt;&lt;/p&gt;

&lt;p&gt;既然存在这样的内存模型，那么在具体的多线程读写中，会发生什么问题呢？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;可见性问题&lt;/p&gt;

    &lt;p&gt;因为在线程对变量进行读写时，首先从主内存中将数据复制到自己的工作内存中，在自己的工作内存中进行写操作后，在刷新回主内存。由于主内存是共享的，工作内存是私有的，因此在这二者之间就存在着隔离，就会导致其他线程的读写不一致。&lt;/p&gt;

    &lt;p&gt;为了解决可见性问题，保证happen-before语义,有很多种方法，比如用volatile，可保证可见性以及阻止局部重排序。以及通过锁机制保证可见性、原子操作等等。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;时序问题&lt;/p&gt;

    &lt;p&gt;我们知道当线程需要一个变量时，先从主内存中获取一个变量，复制到工作内存中进行读写。当这个线程再次需要用到这个变量时，可以从主内存中复制新的过来，或者直接使用工作内存中的变量。假如多个线程同时需要读写这个变量，那这个过程就会存在时序问题。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在多线程的编写中，我们需要保证线程安全，即每次多线程执行结束后操作的结果都是一样的。因此需要用到Java中的同步互斥机制来确保线程安全。&lt;/p&gt;

&lt;h3 id=&quot;synchronized&quot;&gt;2. synchronized&lt;/h3&gt;

&lt;p&gt;synchronized是保证线程同步的关键字。通过使用这个关键字，可以使得被标记的代码在任何时候最多允许一个线程执行这段代码。&lt;/p&gt;

&lt;p&gt;一般有两种用法：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;法一：

public synchronized void method(){
	…………
}

法二：

public int method(){
	synchronized(this){
		…………
	}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这两种方法都能进行控制。当然各有优缺点。由于法一是直接对整个方法进行同步，在进入方法时需要再分配资源，性能会低于法二。&lt;/p&gt;

&lt;p&gt;对于法二，语法为synchronized (object){……}。其中object可以是任意其他对象、this。可以用&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private byte[] lock = new byte [1];
public void method() {
	synchronized (lock){
	……
	}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这种方式比较常用，能减少对锁的新建、释放所需要的资源，提高性能。但是需要&lt;strong&gt;注意&lt;/strong&gt;的是，在一个class中，所有需要同步的方法都用这个lock对象，这样才能保证线程安全。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;当一个线程访问一个object的一个synchronized同步块时，它将获得整个对象的所有加了同步的方法锁，也就是说即使它没有访问这个对象里其他的同步块，但是其他线程也无法访问那些没被访问的同步块。换句话说，就是对这个对象“包场”了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;lock-and-reentrantlock&quot;&gt;3. Lock and ReentrantLock&lt;/h3&gt;

&lt;p&gt;synchronized关键字提供了隐式锁机制来保证线程同步。当然，java中提供显示锁Lock，可手动进行锁的请求与释放。与synchronized相比，显示锁可操作性更强，功能更强。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Lock相对于synchronized，区别在于Lock是对代码块进行加锁，而synchronized是对对象进行操作，保证对象的互斥。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这里对几种常用锁进行对比&lt;/p&gt;

&lt;h4 id=&quot;reentrantlock&quot;&gt;ReentrantLock&lt;/h4&gt;

&lt;p&gt;这个锁是在工作中用量很大的。主要的好处是更具有伸缩性，当很多线程竞争相同锁时，能够提供相对synchronized更高的吞吐量。主要的缺点就是需要手动释放锁。当然这个是无法避免的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private final ReentrantLock lock = new ReentrantLock();
public void method() {
	lock.lock();
	try{
	……
	}finally{
		lock.unlock();
	}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;readwritelock-and-reentrantreadwritelock&quot;&gt;ReadWriteLock and ReentrantReadWriteLock&lt;/h4&gt;

&lt;p&gt;ReadWriteLock接口，主要用在对于读操作比较多，写操作比较少的情况。相对于ReentrantLock对读写都需要进行互斥保证，ReadWriteLock对读写进行了优化。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;多线程可同时读&lt;/li&gt;
  &lt;li&gt;单线程写&lt;/li&gt;
  &lt;li&gt;有读是不能写，有写时不能读&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ReentrantReadWriteLock是其实现类，实现读锁、写锁的分离使用，能适用更复杂的应用场景&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; private ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock();    //创建锁对象
 private Lock readLock = rwLock.readLock();
 private Lock writeLock = rwLock.writeLock();
    
 public void write(){
        writeLock.lock();
        ……
        writeLock.unlock();
    }
  public int read(){
        readLock.lock();
        ……
        readLock.unlock();
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;stampedlock&quot;&gt;StampedLock&lt;/h4&gt;

&lt;p&gt;StampedLock主要是为了实现悲观锁和乐观锁机制。一般利用StampedLock是为了用作开发线程安全组件的内部工具，吞吐量相对于Lock有很大的改进。但是这个锁有点小复杂，我还对这个还不是很熟，就不细讲了。在一般的应用场景中更主要是运用ReentrantLock系列就足够了。&lt;/p&gt;

&lt;h3 id=&quot;volatile&quot;&gt;4. volatile修饰变量&lt;/h3&gt;

&lt;p&gt;volatile关键字的作用是告诉编译器，这个被修饰的变量是容易变化的，因此不对这个变量使用缓存等优化机制。每次使用时直接从主存中进行读取。&lt;/p&gt;

&lt;p&gt;可以看出volatile提供内存可见性，没有提供原子性。主要可以用在一个变量会有多个线程读，一个线程写的场景下。&lt;/p&gt;

&lt;h3 id=&quot;atomic&quot;&gt;5.原子操作atomic&lt;/h3&gt;

&lt;p&gt;在高并发的环境下非常适合用原子操作。原子操作即是一个操作要么完全执行，要么完全不执行。在Java中提高了多种原子类可供使用，如AtomicInteger\AtomicLong\AtomicBoolean\AtomicReference等等，基本各类的操作大同小异，提供读、写、赋值、自增、自减等等操作。&lt;/p&gt;

&lt;p&gt;原子操作的实现原理为CPU的CAS（比较交换），由于不是我们的关注重点，也就不说了，只需要知道怎么用就行&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;point: 在并发多线程编程中，运用同步锁机制的主要是用于单例模式（Singleton）。在编写时，不仅要考虑线程安全，同时也要尽量提高并发性能。&lt;/p&gt;
&lt;/blockquote&gt;

</description>
        <pubDate>Sun, 19 Jun 2016 22:00:00 +0800</pubDate>
        <link>snail.ren/java-concurrent programming</link>
        <guid isPermaLink="true">snail.ren/java-concurrent programming</guid>
        
        
        <category>concurrent</category>
        
      </item>
    
      <item>
        <title>Java Concurrent Programming2: Thread </title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#thread&quot; id=&quot;markdown-toc-thread&quot;&gt;二、初识Thread&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;1. 线程的实现方法&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;2. 线程一些特性&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;3. 线程生命周期&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;4. 守护线程&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;5.线程组&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#threadlocal&quot; id=&quot;markdown-toc-threadlocal&quot;&gt;6.线程副本ThreadLocal&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-5&quot; id=&quot;markdown-toc-section-5&quot;&gt;7.线程异常处理&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上一部分我们学习了一些关于java并发编程的基础知识，这部分我们先学习一下Java多线程的重要知识－Thread&lt;/p&gt;

&lt;h3 id=&quot;thread&quot;&gt;二、初识Thread&lt;/h3&gt;
&lt;p&gt;本部分主要介绍Java Thread基础知识&lt;/p&gt;

&lt;h5 id=&quot;section&quot;&gt;1. 线程的实现方法&lt;/h5&gt;

&lt;p&gt;在进行java多线程编写时，我们知道是通过java中的Thread进行实现的。那在实现Thread时，有哪几种方法可以实现Thread呢？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;继承Thread父类&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   public class myThread extends Thread{
   	public void run(){    //覆盖run方法
   		super.run();
   	}
   }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;启动&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    myThread thread = new myThread();
    thread.start();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;实现Runnable接口&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class myThread implements Runnable{
        public void run() {   //实现run方法
            //业务逻辑
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;启动&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    myThread thread = new myThread();
    new Thread(thread).start();   // 这里的调用方式不同
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;实现Callable接口&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class myThread implements Callable&amp;lt;String&amp;gt;{
        public void call() {
            //业务逻辑
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;启动&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	myThread thread = new myThread();
    FutureTask&amp;lt;String&amp;gt; feature = new FutureTask&amp;lt;String&amp;gt;(thread);
    new Thread(feature).start(); // 这里的调用方式不同
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;至于应该选择哪种实现方式，各个方式都有自己的优缺点。比如采用直接继承的方式虽然会比较方便一点，但是我们知道java不支持多继承的，如果采用继承接口的方式实现的话就能避免无法多重继承的尴尬。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;point: 三种实现方式各有优缺点，但是主要还是用第二种&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;section-1&quot;&gt;2. 线程一些特性&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;在一个Java多线程的代码中，当代码运行时，main方法本身就会开启一个线程作为主线程。其他在主线程中开启的子线程会在主线程执行开始之后开始执行。但是在结束时，主线程结束了，子线程不一定结束，可能还在继续运行。&lt;/li&gt;
  &lt;li&gt;线程在建立之后，会有一个&lt;strong&gt;&lt;em&gt;优先级&lt;/em&gt;&lt;/strong&gt;属性。在CPU调度时，优先级高的更容易被CPU运行。新建的子进程的优先级和父进程一致，在没有指定时，默认优先级为5（0-10）&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-2&quot;&gt;3. 线程生命周期&lt;/h4&gt;

&lt;p&gt;其实说到生命周期，已经被人说滥了。不过生命周期确实是很重要需要了解的。这里我们也需要再复习一下。
如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/blog/ThreadLife.png&quot; alt=&quot;Thread Life Cycle&quot; /&gt;&lt;/p&gt;

&lt;p&gt;线程共有上图中五种生命周期：new、runnable、running、blocked、dead&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;new&lt;/p&gt;

    &lt;p&gt;当new一个Thread的时候，就新建了一个线程对象， 该线程进入新建状态，分配了内存空间，但是还没有被启动。此时还不是alive。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;runnable&lt;/p&gt;

    &lt;p&gt;当调用start()方法时，启动了线程，进入就绪状态，此时具备运行条件，排队等待被CPU执行。此时就进入了alive状态。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;running&lt;/p&gt;

    &lt;p&gt;调用了run()方法，线程正式开始执行。如果没其他情况（等待IO，被更高级中断……），线程会运行至结束&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;blocked&lt;/p&gt;

    &lt;p&gt;由于某些原因，需要暂停该线程，如等待IO，sleep等&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;dead&lt;/p&gt;

    &lt;p&gt;线程执行完毕或者被杀死&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在线程的运行中，可以被其他进程或者自身中断。Thread提供两种中断机制。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Thread.stop()&lt;/p&gt;

    &lt;p&gt;这种方法太野蛮，强制停止线程，不安全，一般不用&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Thread.interrpt()机制&lt;/p&gt;

    &lt;p&gt;通过线程自身，或者其他线程，可以通过interrupt()方法设置线程的中断信号，线程通过查看自己的线程中断信号是否为true，根据自己的业务逻辑进行响应处理&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-3&quot;&gt;4. 守护线程&lt;/h4&gt;

&lt;p&gt;Java的守护线程我觉得还是很有用的。首先看看守护线程是什么。守护线程就是在后台运行的线程。普通线程结束后，守护线程自动结束。一般main线程为守护线程，以及GC、数据库连接池等，都做成守护线程。&lt;/p&gt;

&lt;p&gt;守护线程的实现非常简单，和普通线程的区别就是在start线程前，执行方法调用setDaemon()。That’s it。是不是超级简单。&lt;/p&gt;

&lt;p&gt;守护线程就像备胎一样，JRE（女神）根本不会管守护线程有没有，在不在，只要前台线程执行结束，就算执行完毕了。&lt;/p&gt;

&lt;h4 id=&quot;section-4&quot;&gt;5.线程组&lt;/h4&gt;

&lt;p&gt;ThreadGroup() 线程组，运行以组的方式管理线程，对一个组进行控制。一个线程组里可以包含子线程和子线程组。最顶级是system线程组。一般在system线程组下的main线程组下面新建线程组。main方法所在的线程就在main线程组。&lt;/p&gt;

&lt;p&gt;线程组和线程池还是有区别的。线程组的目的是为了方便对线程进行管理，线程池的作用是对线程的生命周期进行管理，达到线程重用的目的。&lt;/p&gt;

&lt;h4 id=&quot;threadlocal&quot;&gt;6.线程副本ThreadLocal&lt;/h4&gt;

&lt;p&gt;线程副本是每个线程都有的独立变量副本。每个线程可以维护自己的副本，不会对其他线程造成影响（其实对这个我还不是特别理解。意思就等于线程副本是线程自己的独立本地私有变量，其他线程无法操作吗？大家对这个有知道的麻烦解惑一下）&lt;/p&gt;

&lt;p&gt;线程副本具备在多个线程之间访问隔离，这也就是说具有很好的并发访问性质。因此在某些场景下比synchronize同步机制更加简单、安全&lt;/p&gt;

&lt;h4 id=&quot;section-5&quot;&gt;7.线程异常处理&lt;/h4&gt;

&lt;p&gt;Java线程提供了一个很好的机制，就是在线程中发生的异常，不能抛到线程外面去处理，只能内部先解决。我们知道，异常有checked异常和unchecked异常。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;checked&lt;/p&gt;

    &lt;p&gt;处理这类异常直接用try/catch就行&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;unchecked&lt;/p&gt;

    &lt;p&gt;这类异常需要自定义实现UncaughtexceptionHandler接口自定义处理，然后将其注册到线程上。当发生unchecked异常时就能进行处理。
  实现步骤&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;1.自定义类UnchaughExceptionHandler，在里面实现自己的处理逻辑&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;2.和普通线程一样进行定义&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;3.在执行线程前，进行Handler注册，将其绑定到这个线程&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class myExceptionHandler implements Thread.UncaughtExceptionHandler{ //自定义处理逻辑
    
    @Override
    public void uncaughtException(Thread t, Throwable e) {
        
    }
}
    
    public class myThread implements Runnable{
        @Override
        public void run() {
            //具体逻辑
        }
    }
    
    public static void  main(String[] args)
    {
        myThread mythread = new myThread();
        Thread thread = new Thread(mythread);
        thread.setUncaughtExceptionHandler(new myExceptionHandler());   //注册handler
        thread.start();
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 19 Jun 2016 01:00:00 +0800</pubDate>
        <link>snail.ren/java-concurrent programming</link>
        <guid isPermaLink="true">snail.ren/java-concurrent programming</guid>
        
        
        <category>concurrent</category>
        
      </item>
    
      <item>
        <title>Java Concurrent Programming </title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;一、基础知识&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#cpu&quot; id=&quot;markdown-toc-cpu&quot;&gt;1. 了解自己的CPU&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;2. 线程和进程的区别&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;3. 并行与并发&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;4. 并发量和吞吐量&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;并发量&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#section-5&quot; id=&quot;markdown-toc-section-5&quot;&gt;吞吐量&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;现在的很多应用场景，比如需要提高并发，提高处理能力、效率，加快处理速度等等。而很多人一面对这种问题就会想到分布式解决方案，想到用hadoop。但是有的场景下，只需要用java并发编程就能解决问题。那java并发到底改怎么做，能够处理哪些需求呢？那我们就来一起学习一下java并发编程。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;一、基础知识&lt;/h3&gt;
&lt;p&gt;我们需要了解一些关于并发编程的基础知识&lt;/p&gt;

&lt;h5 id=&quot;cpu&quot;&gt;1. 了解自己的CPU&lt;/h5&gt;

&lt;p&gt;要做并发编程，首先我们得了解我们的机器是否支持多线程，能够支持多少并行线程。当然，决定性的关键在于机器的CPU。&lt;/p&gt;

&lt;p&gt;我们知道，在现在的各类CPU都是多核多线程CPU。那我们该怎么看这个CPU对并发的支持度有多少呢？举个例子。假如我们有个PC，CPU是双核双线程（Intel的超线程技术可使核：线程数＝1:2）。那也就是说我们有2*2条通道。可以想象成我们有四条车道，每条车道都能跑，也就是支持四个线程同时运行。当然，服务器的CPU更多核，更多线程。&lt;/p&gt;

&lt;p&gt;那怎么查看自己的CPU是几核几线程的呢？Linux当然是在/proc/cpuinfo下查看，windows用设备管理器查看，也可以用鲁大师之类的查看。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;point: 通过查看CPU信息，支持并行线程数＝核心数＊单个核支持的线程数&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;section-1&quot;&gt;2. 线程和进程的区别&lt;/h4&gt;

&lt;p&gt;线程和进程在本科期间的操作系统课就有学。先给一个定义：&lt;strong&gt;进程&lt;/strong&gt;是程序运行&lt;strong&gt;资源&lt;/strong&gt;分配的最小单位，&lt;strong&gt;线程&lt;/strong&gt;是&lt;strong&gt;CPU调度&lt;/strong&gt;的最小单位。可能看完这个定义，你跟我一样还是有点懵。没关系，咱们再解释一下。&lt;/p&gt;

&lt;p&gt;打个比方：我们把计算机比作一间仓库。仓库里有很多箱子。每个箱子里装着不同种类和数量的小动物，比如说小狗啊，鱼啊，小猫啊（当然他们都是活的，一个箱子有任意个小动物）。我们就把进程比作这一个个箱子。把线程比作箱子里面的小动物。&lt;/p&gt;

&lt;p&gt;在仓库里，我们要存放小动物，我们需要以箱子为单位给他们提供空间（不能让他们满仓库乱跑吖），箱子里有各类小动物需要的资源，比如水，食物等等。一个箱子里的小动物（线程）可以共享这些资源。但是可以动的（运行）就是这一个个小动物，就是最小的运行单位了。&lt;/p&gt;

&lt;p&gt;进程和线程的区别差不多就是这个比喻这样，进程之间相互独立。&lt;strong&gt;进程&lt;/strong&gt;是具有一定独立功能的程序关于某个数据集合上的一个运行活动，是资源分配和调度的独立单位。&lt;strong&gt;线程&lt;/strong&gt;是进程的一个实体，是CPU调度和分派的基本单位，比进程更小，能独立运行。同属于一个进程内的线程共享资源。&lt;/p&gt;

&lt;h4 id=&quot;section-2&quot;&gt;3. 并行与并发&lt;/h4&gt;

&lt;p&gt;并行与并发经常容易搞混淆。我们说的是并行编程，为什么不说并发编程捏？什么是并行，什么是并发？&lt;/p&gt;

&lt;p&gt;还是打个比方。一条高速公路，有8车道。如果你8个车道同时开通车（线程），同时开的车数量小于等于8，即每条车道一辆车，这几辆实实在在的在同时开动，那么就是&lt;strong&gt;并行&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;并发的意思就是虽然只有8个车道，但是你往车道上放了大于8台车，要一起开动，那也就以为着你需要做调度，安排一下这些车怎么运行。这就是&lt;strong&gt;并发&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;point: 同时运行的线程数 &amp;gt; CPU支持的并行数，则是并发，否则并行。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;section-3&quot;&gt;4. 并发量和吞吐量&lt;/h4&gt;

&lt;h6 id=&quot;section-4&quot;&gt;并发量&lt;/h6&gt;

&lt;p&gt;我们在做并发编程的时候，需要计算一下支持的并发量到底是多少。怎么算呢？并发量的计算需要考虑到很多因素，比如程序占用的带宽、程序占用的内存、CPU调度时间等等。有很多计算方法，这里只给出极限并发量算法，即&lt;strong&gt;理想状态&lt;/strong&gt;，不考虑其他因素时并发量的支持度。&lt;/p&gt;

&lt;p&gt;假如一台服务器2个CPU，每个CPU8核16线程，那一秒内，极限并发量的计算为&lt;/p&gt;

&lt;p&gt;(1000ms* 2 * 8 * 16)/(CPU切片轮换时间（假如10ms）＋程序执行时间（假如10ms）)=1600个并发。&lt;/p&gt;

&lt;p&gt;如果前台不死机，客户最大容忍3s，则这套程序支持的最大并发量为3*1600=4800个并发访问。&lt;/p&gt;

&lt;h6 id=&quot;section-5&quot;&gt;吞吐量&lt;/h6&gt;
&lt;p&gt;吞吐量指对网络、设备、端口、虚电路等设施，在单位时间内成功传输的最大数据量。这里要和带宽区分一下。带宽是在通信链路中，以太网链路支持的最大传输量，但是你的系统中还有其他设施啊，比如接口啊，路由器等等，这些的吞吐量不够的话，整体系统的吞吐量是会减小的，也就是要看吞吐量瓶颈在哪儿，是多少来决定系统的吞吐量&lt;/p&gt;

&lt;p&gt;这里大概就是一些基础知识，我们需要知道分布式、并行、并发的区别，才能正确去运用他们。ok，这一章就酱。&lt;/p&gt;
</description>
        <pubDate>Sat, 18 Jun 2016 19:00:00 +0800</pubDate>
        <link>snail.ren/java-concurrent programming</link>
        <guid isPermaLink="true">snail.ren/java-concurrent programming</guid>
        
        
        <category>concurrent</category>
        
      </item>
    
      <item>
        <title>On the Teiid Architecture </title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#teiidhttpteiidjbossorg-architecture&quot; id=&quot;markdown-toc-teiidhttpteiidjbossorg-architecture&quot;&gt;&lt;a href=&quot;http://teiid.jboss.org/&quot;&gt;Teiid&lt;/a&gt; Architecture&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#view-data&quot; id=&quot;markdown-toc-view-data&quot;&gt;View Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;teiidhttpteiidjbossorg-architecture&quot;&gt;&lt;a href=&quot;http://teiid.jboss.org/&quot;&gt;Teiid&lt;/a&gt; Architecture&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/blog/teiid_architecture.png&quot; alt=&quot;Teiid Client Registry&quot; /&gt;
 ## Connector&lt;/p&gt;

&lt;h2 id=&quot;view-data&quot;&gt;View Data&lt;/h2&gt;
&lt;p&gt;## Translator
## VDB&lt;/p&gt;

</description>
        <pubDate>Wed, 15 Jun 2016 01:00:00 +0800</pubDate>
        <link>snail.ren/teiid-getstart-code</link>
        <guid isPermaLink="true">snail.ren/teiid-getstart-code</guid>
        
        
        <category>teiid</category>
        
      </item>
    
  </channel>
</rss>
